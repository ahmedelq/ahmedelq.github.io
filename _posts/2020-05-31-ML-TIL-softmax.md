---
layout: post
title: Softmax
author: Ahmed Alq
tags: [TIL, ML, DL]
comments : true
 
---

Softmax is a function that turns a vector of numerical values into probabilities, it is used at the output layer to spit probabilities for the different classes in that neural network that add up to 1, In other words, the classes must be mutually exclusive, if not then better use Sigmoid function. Softmax has a nice property: it balances unscaled values. 

## Further reading

* [Wikipedia](https://en.wikipedia.org/wiki/Softmax_function)
* [Understand the Softmax Function in Minutes](https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d) by Uniqtech.
* [The Softmax Function, Simplified](https://towardsdatascience.com/softmax-function-simplified-714068bf8156), by Hamza Mahmood. 



 

 

